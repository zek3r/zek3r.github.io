<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-02-11T19:45:01-05:00</updated><id>/feed.xml</id><title type="html">Computational Cognition</title><subtitle>A website on the mathematical principles of artificial and biological cognition, written by a Mila (Quebec AI institute) PhD student.</subtitle><author><name>Ezekiel Williams</name></author><entry><title type="html">Welcome to Computational Cognition!</title><link href="/jekyll/update/2021/09/15/welcome.html" rel="alternate" type="text/html" title="Welcome to Computational Cognition!" /><published>2021-09-15T01:00:00-04:00</published><updated>2021-09-15T01:00:00-04:00</updated><id>/jekyll/update/2021/09/15/welcome</id><content type="html" xml:base="/jekyll/update/2021/09/15/welcome.html">&lt;p&gt;Welcome to my new website! To learn about me, check out the “author” page; to learn about the website, check out “about”; to contact me or follow me on social media, check out the site footer. First blog post to come soon :)&lt;/p&gt;</content><author><name>Ezekiel Williams</name></author><category term="jekyll" /><category term="update" /><summary type="html">Welcome to my new website! To learn about me, check out the “author” page; to learn about the website, check out “about”; to contact me or follow me on social media, check out the site footer. First blog post to come soon :)</summary></entry><entry><title type="html">Energy Based Models I - Introduction</title><link href="/jekyll/update/2021/09/10/bp1.html" rel="alternate" type="text/html" title="Energy Based Models I - Introduction" /><published>2021-09-10T21:10:02-04:00</published><updated>2021-09-10T21:10:02-04:00</updated><id>/jekyll/update/2021/09/10/bp1</id><content type="html" xml:base="/jekyll/update/2021/09/10/bp1.html">&lt;h2 id=&quot;welcome-to-computational-cognition&quot;&gt;Welcome to Computational Cognition&lt;/h2&gt;

&lt;p&gt;Very excited to start blogging! Check out the About page to learn the purpose of this blog and its intended audience(s), and the Author page to learn about me.&lt;/p&gt;

&lt;h1 id=&quot;mini-series-on-energy-based-models&quot;&gt;Mini-Series on Energy Based Models&lt;/h1&gt;

&lt;p&gt;I am starting this blog with a mini-series of posts on Energy Based Models (EBMs). The profound impact of Energy Based Models (EBMs) on neuroscience and artificial intelligence, along with their mathematical elegance, are reason enough to make them the opening topic. However, I am further motivated to write on this topic because the literature on EBMs bridges many cool domains (will elaborate on these in future posts), there is a revived interest in this class of models\(^{1,2}\), and they are highly relevant to my own PhD work. There were also several questions related to EBM resources at the recent &lt;a href=&quot;https://www.main2021.org/&quot;&gt;Montreal AI and Neuroscience (MAIN) conference&lt;/a&gt;. Perhaps the MAIN attendees behind these questions will find some insight on Computational Cognition :)&lt;/p&gt;

&lt;h1 id=&quot;how-to-read-this-blog&quot;&gt;How to Read This Blog&lt;/h1&gt;

&lt;p&gt;My blog posts will be composed of self-contained modules, each module being geared towards readers who want less, or more, mathematical detail. As such, I intend this to be a choose-your-own adventure where you can pick out what you want to learn. I also aim to make each blog post &lt;em&gt;short&lt;/em&gt;, only 2-3 pages including figures, so that even if you read the whole thing you can do it over half a cup of coffee.&lt;/p&gt;

&lt;h2 id=&quot;what-are-energy-based-models&quot;&gt;What are Energy Based Models?&lt;/h2&gt;

&lt;center&gt;
&lt;figure&gt;
    &lt;img src=&quot;https://zek3r.github.io/assets/bp1/fig1.png&quot; title=&quot;i am artist&quot; /&gt;
    &lt;figcaption&gt; &lt;b&gt;Memories are as low points in the energy function:&lt;/b&gt; An energy function (red line) storing two memories as low points (blue arrow and yellow arrow). Blue/yellow highlight on x-axis denote model states that are associated with blue/yellow memory (attractor basins), and blue/yellow highlighted red line denote related portions of energy function. Y-axis is energy; x-axis is system state.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/center&gt;

&lt;p&gt;An EBM is a mathematical object that uses an energy function (described below) to perform various cognitive tasks. These tasks could include learning, storing and retrieving memories, or representing a probability distribution (I call the latter a cognitive task because the brain can do this at least approximately–see Pouget et al. 2013\(^3\)). In the context of neural-ai, EBMs are usually a form of artificial neural network. In addition to being a mathematical model for biological neural circuits, EBMs have many applications in AI, including image recognition\(^4\), language modelling (if one views transformers as EBMs\(^2\)), and robotics\(^5\)}. EBMs can be divided into two classes: deterministic, lacking randomness, and stochastic, using randomness to perform computations. Today’s blog post will introduce the two categories of EBMs.&lt;/p&gt;

&lt;h1 id=&quot;intuitive-description&quot;&gt;Intuitive Description&lt;/h1&gt;
&lt;p&gt;A deterministic EBM is composed of two parts: a system (e.g. ball rolling on an uneven surface) that can take on any configuration from a set of states (e.g. position of the ball on the surface), and an energy function (e.g. the negative of the potential energy of the ball), that assigns a value, the energy, to each configuration of the system. &lt;strong&gt;A good intuition is to think of the system states as points on a topographical map and the energy function as representing the elevation of each point&lt;/strong&gt;. The system ‘prefers’ to be in states of low energy just as a rock prefers to roll downhill. To store memories, one manipulates the energy function (the contours of the topographic map) so that the state that you want to memorize is at the bottom of a basin in the function and the system states you wish to associate with, or use to evoke, the memory are all inside of the basin. Then, to recall the memory from a memory-evoking state all you have to do is slide down the function, from the location of the evoking-memory, to the bottom of the basin, the location of the evoked memory. You can store multiple memories by making multiple, non-overlapping basins in your energy function. If this all seems too abstract, I wrote a mini story to help with deterministic EBM intuition (see bonus material!).&lt;/p&gt;

&lt;center&gt;
&lt;figure&gt;
    &lt;img src=&quot;https://zek3r.github.io/assets/bp1/fig2.png&quot; title=&quot;cool&quot; /&gt;
    &lt;figcaption&gt; &lt;b&gt;Recalling a memory is done by following the energy function &apos;downhill&apos;:&lt;/b&gt; Given a starting state (white triangle), associated with a point on the energy function (white arrow), the dynamics of the EBM (green arrows by x-axis) follow the energy function &apos;downhill&apos; (green arrows by energy function) to find the memory state (blue triangle), associated with the low point on the energy function (blue arrow), resulting in memory recall. Everything else is as in the previous figure.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/center&gt;

&lt;p&gt;A stochastic EBM uses system and energy function in the same way as the deterministic one; the difference is the way in which the system transitions from one state to another. Given a starting state (position on the topographic map) of the system, the deterministic EBM will always move downhill to low points. Conversely, the stochastic system contains a little randomness: on average it will prefer to spend time in lower energy states but it will sometimes transition to higher states. The physical analogy here is to imagine 3D printing your topographic map so that it forms a surface with little hills and valleys on it. Now imagine shaking the map. The rock will usually stay in the valleys of the 3D map but it will jump around in a random-looking fashion as you shake it and will sometimes move up a hill or out of one valley and into another.&lt;/p&gt;

&lt;h1 id=&quot;mathematical-description&quot;&gt;Mathematical Description&lt;/h1&gt;

&lt;p&gt;Assume you have a model system parameterized by a vector \(w \in \mathbb{R}^p\) and taking values in \(\mathbb{R}^n\). An energy based model is one that uses an energy function \(E : \mathbb{R}^n \times \mathbb{R}^p \mapsto \mathbb{R}\), to map model states (these could be inputs, outputs, and latent variables in the case of a neural network) to a single, scalar, energy value. A deterministic EBM is a dynamical system on \(\mathbb{R}^n\) such that for \(s \in \mathbb{R}_{\geq 0}\) or \(\in \mathbb{N}\) and \(\{x_t\}_{t \in \Omega}\) (where \(\Omega\) could be \(\mathbb{R}\) or \(\mathbb{Z}\)), \(E(x_t) \geq E(x_{t + s})\). For example, if \(E\) is differentiable in \(x\), one could take the dynamics to simply descend the gradient of the energy function&lt;/p&gt;

&lt;p&gt;\begin{align}
    x_{t+1}^{(i)} = x_t^{(i)} -\eta \frac{\partial E(x_t, w)}{\partial x_t^{(i)}}, \quad \quad \quad
    \dot{x}^{(i)} \propto - \frac{\partial E(x, w)}{\partial x^{(i)}}
\end{align}&lt;/p&gt;

&lt;p&gt;for the descrete and continuous time cases respectively, where \(\eta \in \mathbb{R}\) is a parameter and \(i \in \{1,...,n\}\) denotes an entry in the vector \(x\). The energy function is thus a Lyapunov function for the EBM’s dynamical system.&lt;/p&gt;

&lt;p&gt;Note that the above definition of the deterministic EBM could be considered restrictive: certain machine learning algorithms that don’t explicitly use energy functions to store and dynamically retrieve memories could still be seen as implicitly shaping an energy function, related to the loss function, during training. See cited tutorial for details\(^6\).&lt;/p&gt;

&lt;p&gt;A stochastic EBM replaces the dynamical system with a probability distribution such that the model system samples states randomly. Hypothetically, given the energy function, one could define a probability distribution in any number of ways. In the literature the probability distribution is almost always taken to be the Gibbs distribution associated with the energy function:&lt;/p&gt;

&lt;p&gt;\begin{align}
    p(x; w) &amp;amp;= \frac{1}{Z}\exp^{-\beta E(x,w)}
\end{align}&lt;/p&gt;

&lt;p&gt;where \(Z\) is the appropriate partition function and \(\beta\) is a parameter with the physical meaning of inverse temperature. This makes sense because as \(\beta\) increases the probability distribution becomes more and more peaked around values of low energy until, at zero temperature (\(\beta = \infty\)) the probability distribution becomes a dirac at the low point of the energy function, just as a physical system at zero energy would exhibit zero movement.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;So far I have introduced the notion of deterministic and stochastic EBMs and of recalling previously learned memories. The next blog post will describe the two classic neural-ai EBMs–the deterministic Hopfield model and the stochastic Boltzmann machine–before discussing how a memory can be &lt;em&gt;learned&lt;/em&gt;. \(\sim\) Zeke&lt;/p&gt;

&lt;h2 id=&quot;bonus-material&quot;&gt;Bonus Material&lt;/h2&gt;

&lt;h1 id=&quot;brief-history&quot;&gt;Brief History&lt;/h1&gt;

&lt;p&gt;EBMs were first studied outside the neural-ai domain, in mathematical physics. The classical example of this is the Ising model, a model of the interactions between atoms in a magnetic substance\(^7\). William Little introduced EBMs to neuroscience (to my knowledge this is the first appearance of EBMs in neural-ai–email me if you know otherwise!) by noting connections between the Ising model and neural networks for memory in 1974\(^8\). This notion was further developed and popularized by John Hopfield in 1982\(^9\), after which EBMs were heavily studied in both neuroscience and AI until the early 2000s (see, e.g. work by Hinton and others\(^{10,11}\)). Around this time, difficulties with training large EBMs (EBMs with many neurons) relegated them to a more pedagogical role in the fields, but recent advances in training\(^1\) coupled with connections to state-of-the-art machine learning models\(^2\) has ushered in a renewed interest in this classic model in recent times.&lt;/p&gt;

&lt;h1 id=&quot;of-ebms-and-amphibians&quot;&gt;Of EBMs and Amphibians&lt;/h1&gt;
&lt;p&gt;Imagine you are a stylish toad. Every Saturday you need to remember that it’s time to start dressin’ in preparation for a night on the town. However, you are lackadaisical and hate to have to remember much, let alone what weekday it is. Your friend frog is a phenomenal meteorologist and tells you that a single rain drop will fall on your Lily pad every Saturday in roughly the same region that a rain drop fell last Saturday. You’ll never forget the position of last Saturday’s rain drop (last Saturday was quite memorable), but you don’t want to have to associate the sight of a droplet at any other point on your lily pad with the memory of last week’s drop (way too much to remember). If only the rain would always fall on last Saturday’s spot, than you could just remember that a rain drop at that location means it’s time to start dressin’! Thankfully, you are well versed in AI: you press down on your lily pad around the region where last Saturday’s drop fell, making a little depression. Now, when the rain drop falls near your memory of last Saturday’s drop, the shape of the pad will make the drop run down to the position of your memory, telling you it’s Saturday! You just turned your lily pad into an energy based model to associate the stimuli of the rain drop at different parts of your pad with your memory that it’s time to start dressin’. The system state is given by the position of the rain drop and the energy function is given by the shape of the lily pad.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Du, Y. &amp;amp; Mordatch, I. Implicit generation and generalization in energy-based models. (2019)&lt;/li&gt;
  &lt;li&gt;Ramsauer, H.et al.Hopfield networks is all you need. (2020)&lt;/li&gt;
  &lt;li&gt;Pouget, A., Beck, J. M., Ma, W. J. &amp;amp; Latham, P. E. Probabilistic brains: knowns and unknowns. (2013)&lt;/li&gt;
  &lt;li&gt;Fischer, A. &amp;amp; Igel, C. Training restricted Boltzmann machines: An introduction. (2014)&lt;/li&gt;
  &lt;li&gt;Haarnoja, T., Tang, H., Abbeel, P. &amp;amp; Levine, S. Reinforcement learning with deep energy-based policies. (2017)&lt;/li&gt;
  &lt;li&gt;LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M. &amp;amp; Huang, F. A tutorial on energy-basedlearning. (2006)&lt;/li&gt;
  &lt;li&gt;Brush, S. G. History of the Lenz-Ising model. (1967)&lt;/li&gt;
  &lt;li&gt;Little, W. A. The existence of persistent states in the brain. (1974)&lt;/li&gt;
  &lt;li&gt;Hopfield, J. J. Neural networks and physical systems with emergent collective computational abilities. (1982)&lt;/li&gt;
  &lt;li&gt;Ackley, D. H., Hinton, G. E. &amp;amp; Sejnowski, T. J. A learning algorithm for Boltzmann machines. (1985)&lt;/li&gt;
  &lt;li&gt;Hinton, G. E. Training products of experts by minimizing contrastive divergence. (2002)&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Ezekiel Williams</name></author><category term="jekyll" /><category term="update" /><summary type="html">Welcome to Computational Cognition</summary></entry><entry><title type="html">Decoding Messages in the Brain</title><link href="/jekyll/update/2021/09/10/msc-paper.html" rel="alternate" type="text/html" title="Decoding Messages in the Brain" /><published>2021-09-10T21:10:02-04:00</published><updated>2021-09-10T21:10:02-04:00</updated><id>/jekyll/update/2021/09/10/msc-paper</id><content type="html" xml:base="/jekyll/update/2021/09/10/msc-paper.html">&lt;h1 id=&quot;decoding-the-language-of-the-brain&quot;&gt;Decoding the Language of the Brain&lt;/h1&gt;
&lt;p&gt;Welcome to my first blog post! My first few posts will be about the peer-review publications that I have contributed to during my Masters and PhD thus far. Today’s blog is about my MSc thesis paper: &lt;strong&gt;&lt;em&gt;&lt;a href=&quot;https://www.nature.com/articles/s41598-021-95037-z&quot;&gt;Neural Burst Codes Disguised as Rate Codes&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;, a title which will hopefully make sense by the end of this post!&lt;/p&gt;

&lt;h2 id=&quot;the-big-picture-background&quot;&gt;The Big Picture (Background)&lt;/h2&gt;

&lt;p&gt;At a high level, the research question asked by my MSc paper is &lt;em&gt;how can we understand the language of the brain?&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-language-of-brain-cells&quot;&gt;The language of brain cells&lt;/h3&gt;

&lt;center&gt;
&lt;figure&gt;
    &lt;img src=&quot;https://zek3r.github.io/assets/msc/blogpost_fig1.jpg&quot; title=&quot;i am artist&quot; width=&quot;600&quot; /&gt;
    &lt;figcaption&gt; &lt;b&gt;Neurons speak in &quot;spikes&quot;:&lt;/b&gt; A neuron receives electrical input from other neurons via its &apos;branches&apos; (known as dendrites) and sends electrical signals to other neurons via its &apos;trunk&apos; (axon), using a tree analogy. The membrane voltage in the axon of neuron A is plotted as a function of time in the bottom left.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/center&gt;

&lt;p&gt;Your brain is composed of about 86 billion neurons–brain cells which are believed responsible for performing the computations that allow you to see, smell, think, talk, walk, and generally experience cognitive phenomena. To do this, these neurons communicate with each other, kind of like how a group of friends might text eachother to coordinate their work on a school project. However, while text chats are composed of words, neuron conversation is composed of electrical pulses that neuroscientists refer to as &lt;em&gt;action potentials&lt;/em&gt;, or &lt;em&gt;“spikes”&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;why-we-want-to-decode-brain-cell-messages&quot;&gt;Why we want to decode brain cell messages&lt;/h3&gt;

&lt;p&gt;Modern science doesn’t fully understand how to read the neural “spike language”. This is an important problem because if we could decode the spike-written messages between neurons, we would be one big step closer to understanding the brain, and could potential solve medical problems–for example being able to control prosthetic devices just by thinking.&lt;/p&gt;

&lt;h3 id=&quot;how-neuroscientists-think-about-brain-cell-messages&quot;&gt;How neuroscientists think about brain cell messages&lt;/h3&gt;

&lt;center&gt;
&lt;figure&gt;
    &lt;img src=&quot;https://zek3r.github.io/assets/msc/blogpost_fig2.jpg&quot; title=&quot;what font is this&quot; width=&quot;600&quot; /&gt;
    &lt;figcaption&gt; &lt;b&gt;Rate vs. temporal codes:&lt;/b&gt; For a rate code, the spike sequence in plot A is the same as that of plot B, but not plot C. For a temporal code, the ISI (distance between consecutive spikes) matters (see plot A)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/center&gt;

&lt;p&gt;There are many theories for how to read the neural language, or “code”. These theories can be divided into two categories: &lt;strong&gt;rate codes&lt;/strong&gt; and &lt;strong&gt;temporal codes&lt;/strong&gt;. Rate code theories say that the only important aspect of the spike messages that a given neuron, neuron ‘A’, sends to another, neuron ‘B’, is the &lt;em&gt;rate&lt;/em&gt; of spikes. If neuron A sends 1 spike every second for 3 seconds, then neuron B will see that neuron A’s spike rate is 3 spikes per second, and this will mean something &lt;em&gt;different&lt;/em&gt; to neuron B than if A had sent neuron B 2 spikes per second during each of the three seconds–a spike rate of 2 spikes per second–but will have the same meaning as if neuron A had send 3 spikes to neuron B in the first second and no spikes in the next two seconds: 3 spikes in 3 seconds gives the same rate no matter which specific times within the three second window the spikes are sent.&lt;/p&gt;

&lt;p&gt;Conversely, temporal coding theories say that the relative timing of the spikes does matter: that is, when neuron A sends 3 spikes in the first second this is different than if A had distributed its spikes evenly in time, first spike at second 1, the second spike one second later at second 2, the third two seconds later at second 3. In this way, in a temporal code, when A sends 2 spikes separated by 1 second this would represent a different word than if A had sent B two spikes separated by 2 seconds $^\dagger$ .&lt;/p&gt;

&lt;p&gt;My research paper looked at addressing a key question that appears in a certain class of temporal codes–how to resolve ambiguity between spike sequences.&lt;/p&gt;

&lt;h3 id=&quot;ambiguity-in-bursty-brain-cell-messages&quot;&gt;Ambiguity in bursty brain cell messages&lt;/h3&gt;

&lt;center&gt;
&lt;figure&gt;
    &lt;img src=&quot;https://zek3r.github.io/assets/msc/blogpost_fig3.jpg&quot; title=&quot;what font is this&quot; width=&quot;600&quot; /&gt;
    &lt;figcaption&gt; &lt;b&gt;Ambiguity of burst codes:&lt;/b&gt; In plot A, spikes close together--small ISIs--are clearly a burst, spikes far apart--big ISIs--a clearly not a burst, but what about &apos;medium&apos; ISIs? One can plot the frequency of occurence of a given ISI, or probability of an ISI occurring, for a given cell, as in plots B and C. Plot B shows not very many medium ISIs, so it&apos;s unambiguous. Alternatively, plot C has many medium ISIs, so it&apos;s very ambiguous!&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/center&gt;

&lt;p&gt;Imagine that you have a temporal code where spikes that occur really close together mean something different from spikes that occur farther apart. This kind of code is called a &lt;em&gt;burst code&lt;/em&gt; because two or more spikes close together in time–bursts of spikes–mean something different than other, more spread out, spike sequences. Messages sent using this code will be easy to read if spikes only occur &lt;em&gt;very&lt;/em&gt; far apart–making them clearly non-bursts–or &lt;em&gt;very&lt;/em&gt; close together–making them clearly bursts. But what if they occur intermediate distances apart? If there is no hard threshold between what is considered a &lt;em&gt;“burst”&lt;/em&gt; and what isn’t, then when neuron A sends neuron B spikes with time gaps of an intermediate length, there will be ambiguity when neuron B tries to understand what neuron A said because it won’t know if the spikes were a burst or not.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;An analogy: imagine two friends, Bob and Alice, and that Bob is listening to Alice. Further imagine that Alice has a short attention span and is very rapidly switching back and forth between telling Bob about a performance of the nut cracker and explaining to Bob why almond milk is less sustainable than oat milk. To make it easier to tell when Alice is describing ballet or milk-alternatives, she talks about the former in french and the latter in english. &lt;strong&gt;However&lt;/strong&gt;, there are many words that are the same between english and french, so when Alice says “festival”, it may not be clear to Bob whether this is a dance festival or a festival of flavours on the tongue brought on by a tasty milk alternative. These words that are the same in french and english are analogous to the spikes that are of intermediate distance apart, which we can’t immediately classify as bursts or non-bursts.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Importantly, experimental evidence shows that these ambiguous, intermediatly-spaced spikes occur frequently in the brain. It is thus an important question for neuroscientists whether neuron B can decode enough of the message from neuron A even with this ambiguity. If not, then neuroscientists will be able to scratch burst codes from the list of possible theories for reading the language of the brain.&lt;/p&gt;

&lt;h2 id=&quot;what-we-did-in-my-msc-paper&quot;&gt;What we did in my MSc Paper&lt;/h2&gt;

&lt;p&gt;Our specific research question was whether neuron A can communicate effectively with neuron B, even when there is ambiguity in whether a sequence of spikes can be considered a burst or not.&lt;/p&gt;

&lt;h3 id=&quot;our-research-methods&quot;&gt;Our research methods&lt;/h3&gt;

&lt;p&gt;To answer this question, we needed a way of quantifying how well neuron B can decode neuron A’s spikes as a function of how much ambiguity there is A’s spike messages. We took a computational approach to answer this question, meaning that we came up with a mathematical model of neurons A and B–a set of equations describing the spikes that A produces and the machinery that B uses to decode those spikes–and analyzed a computer simulation of this model. In this model, we could vary the amount of ambiguity in A’s messages. We then used tools from &lt;strong&gt;information theory&lt;/strong&gt; to quantify how well neuron B could, in theory, decode neuron B’s messages. Information theory is a branch of mathematical statistics that quantifies the amount of variability in a variable–where a variable could be the message that one neuron sends to another, for example–and how much the variability in one variable says about the variability in another. If the variability in neuron B’s decoding of neuron A’s message says a lot about A’s original message, then neuron A is communicating well with neuron B!&lt;/p&gt;

&lt;h3 id=&quot;our-findings-and-why-they-are-useful&quot;&gt;Our findings and why they are useful&lt;/h3&gt;

&lt;p&gt;We found that, in certain cases, neuron A can communicate quite effectively with neuron B, even when there is ambiguity between what spike pairs should be considered bursts, and which should be considered non-bursts! Interestingly, in such cases, the statistics of neuron A’s spiking look very similar to how they would look if neuron A was using a rate code. This means that if an experimentalist records neuron activity in the brain and finds that a neuron’s spiking looks like a rate code it might actually be stealthily using a temporal, bursting code! Hence the name of the paper.&lt;/p&gt;

&lt;p&gt;For a brief overview of some of the math used, and for some key references, see below. Thanks for reading!&lt;/p&gt;

&lt;h2 id=&quot;math-overview&quot;&gt;Math Overview&lt;/h2&gt;

&lt;h3 id=&quot;neural-circuit-model&quot;&gt;Neural Circuit Model&lt;/h3&gt;
&lt;p&gt;I’m not including the equations in this section as they are bulky and don’t provide too much intution. See the &lt;a href=&quot;https://www.nature.com/articles/s41598-021-95037-z&quot;&gt;supp of our paper for them&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For neuron A, we formulated a new bursting model, the Burst Spike Response Model, inspired by the &lt;a href=&quot;https://en.wikipedia.org/wiki/Spike_response_model&quot;&gt;Spike Response Model of Gerstner et al&lt;/a&gt; and &lt;a href=&quot;https://www.pnas.org/doi/abs/10.1073/pnas.1720995115&quot;&gt;previous work&lt;/a&gt; by my MSc supervisor Richard Naud. Mathematically, the model is a point process determined by an event rate and a burst probability: the former determines how often spikes occur and the latter determines whether or not a rapidly-occurring burst spike occurs after the original spike. In neuro-theory language, this is a two compartment model with stochastic spiking, where the first (dendritic) compartment encodes the burst probability and the second somatic compartment encodes the event rate&lt;/li&gt;
  &lt;li&gt;The inputs to neuron A are &lt;a href=&quot;https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process&quot;&gt;Ornstein-Uhlenbeck processes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Neuron B is modelled as a nonlinear function of the linearly filtered spike train of neuron A&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;info-theory-analysis&quot;&gt;Info Theory Analysis&lt;/h3&gt;
&lt;p&gt;To quantify information transmitted we used the mutual information rate, $\mathbb{I}$, a generalization of mutual information from random varaibles to stochastic processes:&lt;/p&gt;

\[\mathbb{I}(X, Y) = \lim_{T \to \infty}\frac{1}{T}I(X_{0:T};Y_{0:T}),\]

&lt;p&gt;where $X$ and $Y$ are stochastic processes and $I(X_{0:T};Y_{0:T})$ is the mutual information between the vector $X_{0:T} = [X_0, …, X_T]$ and $Y_{0:T} = [Y_0, …, Y_T]$.&lt;/p&gt;

&lt;p&gt;This quantity is a massive hassle to compute, but one can compute a linear lower-bound for this information rate as:&lt;/p&gt;

\[-\int_0^{\frac{1}{2}}\log_2\big(1 - \Phi_{XY}(f)\big)\mathrm{d}f,\]

&lt;p&gt;where $\Phi_{XY}$(f) is the coherence between $X$ and $Y$ and $f$ is frequency (see &lt;a href=&quot;https://www.cell.com/biophysj/pdf/S0006-3495(72)86087-9.pdf&quot;&gt;Stein et al.&lt;/a&gt;). We used this to quantify information transmitted in the paper.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;p&gt;For further reading on a given topic, see below (papers are author first; textbooks are title first):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Neural coding:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://neuronaldynamics.epfl.ch/online/Ch7.S6.html&quot;&gt;Neural Dynamics Ch. 7.6&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.researchgate.net/publication/14678604_Theunissen_F_Miller_J_P_Temporal_encoding_in_nervous_systems_a_rigorous_definition_J_Comput_Neurosci_2_149-162&quot;&gt;Theunissen &amp;amp; Miller, Temporal encoding in nervous systems: a rigorous definition&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Neural_coding&quot;&gt;Wikipedia, Neural Coding&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Burst coding
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.pnas.org/doi/abs/10.1073/pnas.1720995115&quot;&gt;Naud &amp;amp; Sprekeler, Sparse bursts optimize information transmission in a multiplexed neural code&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://nelson.beckman.illinois.edu/pubs/Krahe_Gabbiani04.pdf&quot;&gt;Krahe &amp;amp; Gabbiani, Burst Firing in Sensory Systems&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Modelling neurons
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://neuronaldynamics.epfl.ch/online/index.html&quot;&gt;Neural Dynamics&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Information theory
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf&quot;&gt;Elements of Information Theory, Cover &amp;amp; Thomas&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Information theory applied to neuroscience
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cns.nyu.edu/csh/csh06/PDFs/BorstTheuneissenNN1999.pdf&quot;&gt;Borst &amp;amp; Theunissen, Information Theory and Neural Coding&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cell.com/biophysj/pdf/S0006-3495(72)86087-9.pdf&quot;&gt;Stein et al., The frequency response, coherence, and information capacity of two neuronal models&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mitpress.mit.edu/9780262181747/spikes/&quot;&gt;Spikes, by Rieke &amp;amp; Bialek, is great but I don’t know of a free pdf&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nature.com/articles/s41598-021-95037-z&quot;&gt;Neural Burst Codes Disguised as Rate Codes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;in-blog-footnotes&quot;&gt;In-blog footnotes&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;$\dagger$ : one may notice that the difference between rate and temporal codes is a little more subtle than described above. One could imagine a situation where the stimulus being encoded in the firing rate of cell ‘A’ changes very quickly, and the downstream cell decoding A’s message is very sensitive to each spike. In this case, even with a rate code small differences in spike timing could convey information. In this way, the &lt;em&gt;real&lt;/em&gt; distinction between rate and temporal codes depends on whether there is information in cell A’s spike train at higher frequencies than those of the stimulus that cell A is encoding.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;     &lt;/p&gt;</content><author><name>Ezekiel Williams</name></author><category term="jekyll" /><category term="update" /><summary type="html">Decoding the Language of the Brain Welcome to my first blog post! My first few posts will be about the peer-review publications that I have contributed to during my Masters and PhD thus far. Today’s blog is about my MSc thesis paper: Neural Burst Codes Disguised as Rate Codes, a title which will hopefully make sense by the end of this post!</summary></entry><entry><title type="html">Energy Based Models II - Hopfield Network</title><link href="/jekyll/update/2021/01/01/bp2.html" rel="alternate" type="text/html" title="Energy Based Models II - Hopfield Network" /><published>2021-01-01T20:10:02-05:00</published><updated>2021-01-01T20:10:02-05:00</updated><id>/jekyll/update/2021/01/01/bp2</id><content type="html" xml:base="/jekyll/update/2021/01/01/bp2.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is the second blog post in a mini-series on Energy Based Models (EBMs). In today’s post I will describe the classic deterministic EBM studied in neural-ai: the Hopfield model. This will ground the previous, introduction to EBMs, blog post in a concrete example and build on the last post by discussing not only how memories are retrieved but how they might be learned.&lt;/p&gt;

&lt;h2 id=&quot;hopfield-model---intuition&quot;&gt;Hopfield Model - Intuition&lt;/h2&gt;

&lt;p&gt;As with any artificial neural network, the Hopfield model can be conceptualized as a collection of neurons, which process information, connected to one another by synapses, which transmit information from neuron to neuron. The core components of the network are the neuron activations, a list (vector) of numbers, one for each neuron, describing how active a given neuron is at the given moment, another list (matrix) of numbers containing the strength of every connection in the network, and, lastly, a third list (vector) of numbers that gives the baseline activity of each neuron (which can alternatively be viewed as a constant input to each neuron). As with any mathematical model, the Hopfield model makes a bunch of abstractions; these are simplifications that only partially capture the features of a real biological network, made so that one can construct a concise mathematical description that is tractable (can actually be analyzed).&lt;/p&gt;

&lt;h1 id=&quot;model-structure-and-connections-to-biology&quot;&gt;Model Structure and Connections to Biology&lt;/h1&gt;

&lt;p&gt;Diving deeper into the structure of the model, the first thing to note is that it is recurrent, meaning that there are loops in the connection pattern between the neurons such that if you follow the synapses leading out of one neuron you could eventually trace a path back to that same neuron through other synapses. This is true to form biologically because many brain circuits are recurrent. The pattern of connections, or &lt;em&gt;connectivity&lt;/em&gt;, in the model is symmetric, meaning that if neuron \(a\) has a synapse leading to neuron \(b\), neuron \(b\) has a connection of equal strength leading to neuron \(a\). This does not necessarily occur biologically, but simplifies the mathematical analysis in a big way (see Chapter 7 of Dayan and Abbott - CITE). Notably, the Hopfield network fails to satisfy Dale’s law (CITE): the synapses leading out of a neuron can be inhibitory, decreasing the activity of the downstream, post-synaptic, neuron or excitatory, increasing its activity. In the brain, neurons can only be excitatory or inhibitory, but not both (as with everything there is actually an exception to this rule (CITE)). At the single neuron level, a each neuron linearly sums the inputs it receives from other neurons, a ubiquitous modelling choice in artificial neural networks that, again, frequently fails to hold true in the brain (CITE nonlinear summation). Finally, the network activations can only take two values: $1$, meaning the neuron is firing an action potential, or $-1$, meaning it is at rest. The AI community usually replaces $-1$ with $0$, a difference that affects the math in a minor way (as I will discuss below) but not the behaviour of the network. In spite of the many simplifications inherent in the Hopfield model, it has provided a wealth of theoretical insights that have driven forward the fields of neuroscience and AI (CITE).&lt;/p&gt;

&lt;h1 id=&quot;retrieving-memories&quot;&gt;Retrieving Memories&lt;/h1&gt;

&lt;p&gt;As an EBM, the Hopfield model takes an initial network state–a set of neuron activations (recall this is a list of \(1\)s and \(-1\)s denoting which neurons are active and which aren’t)–and iteratively updates this network state by changing the activations of the neurons in such a way as to slide down the contour of the energy function, retrieving a previously stored memory. Thus, through updates, the initial network state is associated with the stored memory, the state that the system converges to. A single neuron updates its state by summing its own constant input (its baseline activity) and the input provided to it by all the other neurons with which it is connected. The latter input is given by a sum over the connected neurons’ activations, with each activation weighted according to the strength of the connection between the given neuron and the neuron who’s activity we are updating. For example, if the neuron we wish to update is connected with neuron \(a\) and neuron \(b\) only, neuron \(a\) has activity \(1\), neuron \(b\) has activity \(-1\), and the weights (synaptic strengths) between these neurons and the updating neuron are \(1/2\) and \(1/4\) respectively, the input to the updating neuron will be \(1/2 \times 1 + 1/4 \times (-1) = 1/4\). To update the entire network, one can either update all neurons at once or a single neuron at a time, referred to as &lt;em&gt;synchronous&lt;/em&gt; and &lt;em&gt;asynchronous&lt;/em&gt; updating respectively. It can be shown that, through performing these updates, the network will eventually converge to a &lt;em&gt;fixed point&lt;/em&gt; (CITE), meaning that if one applies the update rule again it will not change the pattern of activations. This fixed point is a low point of the energy function and, thus, represents a stored memory.&lt;/p&gt;

&lt;h1 id=&quot;learning-memories&quot;&gt;Learning Memories&lt;/h1&gt;

&lt;p&gt;At this point I have described the network structure and how to retreive memories. The natural follow up question is how to learn a memory; stated alternatively, how to embed a low point in the energy function of the Hopfield network. Just like in the brain, memories are stored in the strengths of the connections between the neurons, which makes sense as the synapses control how information is passed between neurons in the network and, thus, the path that the updates in the network will follow towards a fixed point in the retrieval process. To “learn” a single memory, the network connection strengths are changed so that each is equal to the product of the activations of the two connected neurons, when the network activations are set to the memory pattern. If two neurons have equal activations for the memory pattern then the synapse strength between them will be $1$; if they have opposite activations the synapse strength will be $-1$. To store more than one memory, one simply takes the average over the synapse strengths dictated by each of the memories one wishes to store. This learning rule might sound familiar to those who have taken a first year psych or neuroscience course, as it dictates that neurons that have the same activations for many memories will have “strong”, positive, synapses while neurons that tend to have opposing patterns for many memories will have “weak”, negative, synapses. Stated more concisely, this is the classic Hebbian learning rule: “neurons that fire together wire together” (CITE).&lt;/p&gt;

&lt;h2 id=&quot;hopfield-model---math&quot;&gt;Hopfield Model - Math&lt;/h2&gt;

&lt;p&gt;The Hopfield network is a network of \(N\) neurons with activations (see above section) given by \(x \in \{1, -1\}^n\) (the set of all \(n\)-dimensional vectors of \(1\) and \(-1\)). Assume the neurons are connected by synapses in an undirected graph structure such that the strength of the connection from neuron \(j\) to neuron \(i\) is the \(i\)-\(j^\mathrm{th}\) element of the matrix \(W\). Let neuron \(j\), \(j \in \mathbb{R}^N\), have a fixed baseline firing rate (perhaps given by a constant input), defined by the \(j^\mathrm{th}\) element of the vector \(b \in \mathbb{R}^N\). Finally, we denote the sign function \(\sigma : \mathbb{R} \mapsto \mathbb{R}\) by&lt;/p&gt;

\[\sigma(x_j) = 
    \begin{cases} 
      \:\:\: 1 &amp;amp; x_j \geq 0  \\
      -1 &amp;amp; x_j &amp;lt; 0 \\
   \end{cases}.\]

&lt;p&gt;In an abuse of notation we will apply \(\sigma\) to vectors, by which we mean that the function is applied element-wise.&lt;/p&gt;

&lt;p&gt;With the above notation, the Hopfield network admits the following energy function&lt;/p&gt;

&lt;p&gt;\begin{align}
    E(x) = - \sum_{i, j} x_i W_{ij} x_j - \sum_j x_j b_j.
\end{align}&lt;/p&gt;

&lt;p&gt;The astute reader will notice that, for appropriate choices of \(W\) and \(b\), this energy function can be viewed as a second order Taylor approximation of any twice differentiable function mapping \(\mathbb{R}^n\) to \(\mathbb{R}\). Noting that the gradient of a first or zeroth order Taylor approximation would yield unchanging dynamics, it becomes clear that the Hopfield model is effectively the simplest, if we take “simple” to mean having the lowest order energy function, EBM yielding nontrivial dynamics.&lt;/p&gt;

&lt;p&gt;The dynamics of the EBM are given by&lt;/p&gt;

\[x_{t+1}^i = \sigma\Big(\sum_j W_{ij}x_t^j + b_i\Big),\]

&lt;p&gt;where \(t \in \mathbb{Z}\), we have used subscript to denote time and superscript neuron index.&lt;/p&gt;

&lt;p&gt;Lastly, to embed \(M\) memories, \(\{v_m\}_{m \in \{1,...,M\}}\) in the energy function one defines the weight matrix as follows:&lt;/p&gt;

\[W = \frac{1}{M}\sum_{m=1}^M x_m x_m^\top,\]

&lt;p&gt;that is, one takes the average of the outer products of the state vectors representing memories.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;In the last blog post we introduced EBMs, and their deterministic and stochastic flavours, and in this post we explored a classic example of a deterministic EBM. The next blog post will discuss the classic stochastic EBM known as the Boltzmann machine. As we will see, these two models are two sides of the same coin in so far as they are deterministic and non-deterministic versions of exactly the same neural network architecture. \(\sim\) Zeke&lt;/p&gt;

&lt;h2 id=&quot;bonus-material&quot;&gt;Bonus Material&lt;/h2&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Du, Y. &amp;amp; Mordatch, I. Implicit generation and generalization in energy-based models. (2019)&lt;/li&gt;
  &lt;li&gt;Ramsauer, H.et al.Hopfield networks is all you need. (2020)&lt;/li&gt;
  &lt;li&gt;Pouget, A., Beck, J. M., Ma, W. J. &amp;amp; Latham, P. E. Probabilistic brains: knowns and unknowns. (2013)&lt;/li&gt;
  &lt;li&gt;Fischer, A. &amp;amp; Igel, C. Training restricted Boltzmann machines: An introduction. (2014)&lt;/li&gt;
  &lt;li&gt;Haarnoja, T., Tang, H., Abbeel, P. &amp;amp; Levine, S. Reinforcement learning with deep energy-based policies. (2017)&lt;/li&gt;
  &lt;li&gt;LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M. &amp;amp; Huang, F. A tutorial on energy-basedlearning. (2006)&lt;/li&gt;
  &lt;li&gt;Brush, S. G. History of the Lenz-Ising model. (1967)&lt;/li&gt;
  &lt;li&gt;Hopfield, J. J. Neural networks and physical systems with emergent collective computational abilities. (1982)&lt;/li&gt;
  &lt;li&gt;Ackley, D. H., Hinton, G. E. &amp;amp; Sejnowski, T. J. A learning algorithm for Boltzmann machines. (1985)&lt;/li&gt;
  &lt;li&gt;Hinton, G. E. Training products of experts by minimizing contrastive divergence. (2002)&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Ezekiel Williams</name></author><category term="jekyll" /><category term="update" /><summary type="html">Introduction</summary></entry></feed>